{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fa3d9ed-9342-4a50-8c8f-b6e3ad16373d",
   "metadata": {},
   "source": [
    "# Case Study 3 - Select optimal survey locality\n",
    "## Description \n",
    "Based on a mix of environmental parameters and a set of existing sample sites, select the site that adds the greatest environmental variation to those already sampled. This case study uses a set of environmental parameters for New South Wales and an inital set of ten random locations within the state and then selects an 11th to maximise environmental variability.\n",
    "\n",
    "## Data Sources\n",
    "The primary goal for this case study is to demonstrate being able to import a set of environmental values for different sites and then use these to identify a subset that maximises spread across the various environmental dimensions.\n",
    "\n",
    "This is a simple implementation that uses four environmental attributes imported for all Australia (or a subset like NSW) at a moderate grid scale:\n",
    "\n",
    "1. Soil water pH (0-5cm) - see https://esoil.io/TERNLandscapes/Public/Pages/SLGA/ProductDetails-SoilAttributes.html\n",
    "2. Soil organic carbon (0-5cm) - see https://esoil.io/TERNLandscapes/Public/Pages/SLGA/ProductDetails-SoilAttributes.html\n",
    "3. Annual mean rainfall\n",
    "4. Annual mean temperature\n",
    "\n",
    "Notes:\n",
    "- The first two can be imported directly as layers from SLGA. The others are probably available online in suitable forms at a slightly better grid resolution and can also be imported directly.\n",
    "- An enhancement to this case study would be to start by importing annual layers (say for the last 5 or 10 years) for each of the weather variables and then generating the mean, maximum and minimum respectively for each pixel across the selected years. These computed results would then be the inputs to the main datacube.\n",
    "- Latitude and longitude could also be incorporated for use directly as additional variables.\n",
    "\n",
    "## Dependencies\n",
    "- This notebook requires Python 3.10 or higher\n",
    "- Install relevant Python libraries with: **pip install mccn-engine rocrate**\n",
    "- Installing mccn-engine will install other dependencies\n",
    "\n",
    "## Overview\n",
    "1. Generate STAC metadata for layers from predefined configuratiion\n",
    "2. Load data cube and exclude nodata values\n",
    "3. Scale all variables to a 0.0-1.0 range\n",
    "4. Select four layers for comparison (soil organic carbon 0-30 cm, soil pH 0-30 cm, mean annual rainfall, mean annual temperature)\n",
    "5. Select 10 random points within NSW\n",
    "6. Generate 10 new layers representing standardised environmental distance between one of the selected points and all other points in NSW\n",
    "7. For every point in NSW, find the lowest environmental distance to any of the selected points\n",
    "8. Select the point in NSW that has the highest value for the lowest environmental distance to any selected point - this is the most different point\n",
    "9. Clean up and save results to RO-Crate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fc00e",
   "metadata": {},
   "source": [
    "## Generate STAC metadata\n",
    "Create the STAC catalogue using the configuration files prepared for the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc51186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from stac_generator.factory import StacGeneratorFactory\n",
    "from stac_generator.core.base import StacSerialiser, StacCollectionConfig\n",
    "from pathlib import Path \n",
    "\n",
    "parent_path = Path(__name__).parents[0]\n",
    "config_path = parent_path / \"config.json\"\n",
    "generated_path = parent_path / \"generated\"\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=8) as pool:\n",
    "    generator = StacGeneratorFactory.get_collection_generator(config_path, StacCollectionConfig(id=\"Collection\"), pool=pool)\n",
    "    serialiser = StacSerialiser(generator, generated_path.as_posix())\n",
    "    serialiser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a43108-71d7-443b-b25b-1e1e98ad638a",
   "metadata": {},
   "source": [
    "## Load Data Cube generation\n",
    "Import the data layers into a 100x100 data cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e2844-8507-4801-b513-295ddcf5b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mccn.client import MCCN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = MCCN(endpoint=generated_path/\"collection.json\", shape=100)\n",
    "\n",
    "all_data = engine.load()\n",
    "\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe50db8",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Filter out nodata values from the float32 layers. Then scale all variables to a 0.0 to 1.0 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filtered = all_data.where((all_data > -1e3),np.nan)\n",
    "\n",
    "scaled_data = filtered.copy()\n",
    "\n",
    "# Scale each variable to 0-1 range\n",
    "for var in scaled_data.data_vars:\n",
    "    # Get min and max for the current variable\n",
    "    var_min = float(scaled_data[var].min())\n",
    "    var_max = float(scaled_data[var].max())\n",
    "    \n",
    "    # Apply min-max scaling\n",
    "    scaled_data[var] = (scaled_data[var] - var_min) / (var_max - var_min)\n",
    "\n",
    "    data = scaled_data[var].values\n",
    "\n",
    "    # Print the scaling factors for reference\n",
    "    print(f\"Scaling for {var}: Original range: {var_min:.2f} to {var_max:.2f} -> Scaled range: {float(scaled_data[var].min()):.2f} to {float(scaled_data[var].max()):.2f} (Mean: {np.nanmean(data):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d9c58",
   "metadata": {},
   "source": [
    "## Display selected layers\n",
    "Map the scaled values for four selected environmental variables (mean annual temperature, mean annual rainfaill, soil organic carbon at 0-30 cm, soil pH at 0-30 cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaled_data.temperature_celsius.values[0, :, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaled_data.rainfall_mm.values[0, :, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaled_data.soc_0_30_mean.values[1, :, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaled_data.ph_0_30_mean.values[1, :, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd82e24",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "1. Select 10 random positions across the space selected.\n",
    "2. Goal is to find the optimal position for an 11th site to maximise variation across the environment.\n",
    "3. Scale all environmental layers on a 0.0 to 1.0 scale based on the actual range of values in the layer.\n",
    "4. Treat these layer values as orthogonal axes in a 5-dimensional space. The environmental distance between any two points will be the fifth root of the product of these five numbers.\n",
    "5. Generate 10 new layers, each representing the environmental distance between every pixel and one of the 10 current points.\n",
    "6. Build a new layer that holds the smallest value for each pixel from these 10 layers - that is the environmental distance between that point and the environmentally closest of the 10 current points.\n",
    "7. Find which pixel has the highest value in this final layer - it represents the most environmentally distant point and the one that should next be surveyed.\n",
    "\n",
    "### Find pixels with valies in selected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c418c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calculate environmental distance in 4D environmental space\n",
    "def environmental_distance(point_values, layer_values):\n",
    "    differences = np.abs(point_values - layer_values)\n",
    "    return np.power(np.prod(differences, axis=-1), 1/4)\n",
    "\n",
    "selected_layers = [\n",
    "    scaled_data.soc_0_30_mean.values[1], \n",
    "    scaled_data.ph_0_30_mean.values[1],\n",
    "    scaled_data.rainfall_mm.values[0],\n",
    "    scaled_data.temperature_celsius.values[0]\n",
    "]\n",
    "\n",
    "layer_values = np.stack(selected_layers, axis=-1)\n",
    "\n",
    "# Stack layers into a single array\n",
    "layer_values = np.stack(selected_layers, axis=-1)\n",
    "\n",
    "# Create valid mask (where we have data for all layers)\n",
    "# Exclude both NaN and zero values for SOC and pH (indices 0 and 1)\n",
    "valid_mask = (\n",
    "    ~np.any(np.isnan(layer_values), axis=-1) &  # No NaN values\n",
    "    (layer_values[..., 0] > 0) &                # SOC > 0\n",
    "    (layer_values[..., 1] > 0)                  # pH > 0\n",
    ")\n",
    "\n",
    "valid_indices = np.where(valid_mask)\n",
    "valid_positions_all = list(zip(valid_indices[0], valid_indices[1]))\n",
    "\n",
    "n_valid = len(valid_positions_all)\n",
    "print(f\"Found {n_valid} valid positions in the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6f4b7",
   "metadata": {},
   "source": [
    "### Find 10 random pixels and then an 11th pixel where the environment is most different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "if n_valid == 0:\n",
    "    print(\"Error: No valid positions found. Check your data for NaN values.\")\n",
    "else:\n",
    "    # Use all valid positions if less than 10, otherwise sample 10\n",
    "    n_samples = min(n_valid, 10)\n",
    "    valid_positions = random.sample(valid_positions_all, n_samples)\n",
    "    \n",
    "    print(f\"\\nUsing {n_samples} sampling positions:\")\n",
    "\n",
    "    # Calculate distance layers for each point\n",
    "    distance_layers = []\n",
    "    for pos in valid_positions:\n",
    "        point_values = layer_values[pos[0], pos[1]]\n",
    "        distances = environmental_distance(point_values, layer_values)\n",
    "        distance_layers.append(distances)\n",
    "\n",
    "    # Build minimum distance layer\n",
    "    with warnings.catch_warnings():\n",
    "        # A warning will be generated for pixels without values\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        distance_layers = np.stack(distance_layers, axis=0)\n",
    "        min_distances = np.nanmin(distance_layers, axis=0)\n",
    "\n",
    "    # Find highest value pixel\n",
    "    min_distances[~valid_mask] = np.nan  # Ensure we don't select invalid positions\n",
    "    optimal_position = np.unravel_index(np.nanargmax(min_distances), min_distances.shape)\n",
    "    max_min_distance = min_distances[optimal_position]\n",
    "\n",
    "    for i, pos in enumerate(valid_positions, 1):\n",
    "        values = layer_values[pos[0], pos[1]]\n",
    "        print(f\"  Point {i}: Row: {pos[0]}, Col: {pos[1]} \",\n",
    "              f\"SOC: {values[0]:.3f}, pH: {values[1]:.3f}, \"\n",
    "              f\"Rainfall: {values[2]:.3f}, Temp: {values[3]:.3f}\")\n",
    "\n",
    "    opt_values = layer_values[optimal_position[0], optimal_position[1]]\n",
    "    print(f\"Optimal new sampling location: \",\n",
    "          f\"Row: {optimal_position[0]}, Col: {optimal_position[1]} \",\n",
    "          f\"SOC: {opt_values[0]:.3f}, pH: {opt_values[1]:.3f}, \"\n",
    "          f\"Rainfall: {opt_values[2]:.3f}, Temp: {opt_values[3]:.3f}\")\n",
    "    print(f\"Environmental distance score for new location: {max_min_distance:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9fe72",
   "metadata": {},
   "source": [
    "## Map environmental distance of sample points to rest of NSW\n",
    "For each of the 10 sample points, display the location on a map and colour NSW according to the similarity/distance of each point to the sample point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = len(valid_positions)\n",
    "n_cols = min(3, n_points)\n",
    "n_rows = int(np.ceil(n_points / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "axes = np.array(axes).ravel()  # Convert to 1D array for easier indexing\n",
    "\n",
    "# Create a custom colormap\n",
    "custom_cmap = plt.cm.RdYlGn_r\n",
    "\n",
    "for idx, distance_layer in enumerate(distance_layers):\n",
    "    # Plot each distance layer\n",
    "    im = axes[idx].imshow(distance_layer, \n",
    "                         cmap=custom_cmap,\n",
    "                         vmin=0,\n",
    "                         vmax=np.nanmax(distance_layers))\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=axes[idx])\n",
    "    cbar.set_label('Environmental Distance\\n(Green=Similar, Red=Different)', \n",
    "                   rotation=270, labelpad=15)\n",
    "    \n",
    "    # Mark the reference point\n",
    "    axes[idx].plot(valid_positions[idx][1], valid_positions[idx][0], \n",
    "                  'k*', markersize=15, markeredgecolor='white', markeredgewidth=2,\n",
    "                  label='Reference Point')\n",
    "    \n",
    "    # Add contours\n",
    "    contours = axes[idx].contour(distance_layer, \n",
    "                                levels=5,\n",
    "                                colors='black',\n",
    "                                alpha=0.5,\n",
    "                                linewidths=0.5)\n",
    "    axes[idx].clabel(contours, inline=True, fontsize=8)\n",
    "    \n",
    "    axes[idx].set_title(f'Environmental Distance from Point {idx+1}\\n(y={valid_positions[idx][0]}, x={valid_positions[idx][1]})')\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Hide any unused subplots\n",
    "for idx in range(n_points, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Environmental Distance Maps\\nGreen = Environmentally Similar, Red = Environmentally Different', \n",
    "             size=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad05541",
   "metadata": {},
   "source": [
    "## Map the environmental distance for the selected point\n",
    "Map the environmental distance between each point and the environmentally closest sample point, and show the location of the newly selected point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f125fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot distance map\n",
    "masked_distances = np.ma.masked_array(min_distances, ~valid_mask)\n",
    "im1 = ax1.imshow(masked_distances, cmap='viridis')\n",
    "plt.colorbar(im1, ax=ax1, label='Environmental Distance')\n",
    "\n",
    "ax1.plot([p[1] for p in valid_positions], [p[0] for p in valid_positions], 'r.', \n",
    "         markersize=10, label='Sample Points')\n",
    "\n",
    "ax1.plot(optimal_position[1], optimal_position[0], 'w*', \n",
    "         markersize=25, label='Optimal New Point')\n",
    "ax1.plot(optimal_position[1], optimal_position[0], 'g*', \n",
    "         markersize=15, label='Optimal New Point')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title('Environmental Distance Map')\n",
    "\n",
    "im2 = ax2.imshow(valid_mask, cmap='gray')\n",
    "plt.colorbar(im2, ax=ax2, label='Valid Data')\n",
    "ax2.set_title(f'Valid Data Mask ({n_valid} valid positions)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6447b5",
   "metadata": {},
   "source": [
    "### Cleanup and remove the generated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2c91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "import pandas as pd\n",
    "from rocrate.rocrate import ROCrate\n",
    "from rocrate.model import ComputationalWorkflow, SoftwareApplication, File, Dataset, ContextEntity, Person\n",
    "\n",
    "# Path to this notebook\n",
    "notebook = \"MCCN-CASE 3.ipynb\"\n",
    "\n",
    "# Path to STAC config file\n",
    "config = \"config.json\"\n",
    "\n",
    "# Names for results files\n",
    "datacube_file = \"Site_selection_study.dc\"\n",
    "sites_file = \"Existing_sites.csv\"\n",
    "distances_file = \"Environmental_distances.csv\"\n",
    "\n",
    "# Path to generated RO-Crate results package\n",
    "ro_crate = \"MCCN-CASE 3.RO-Crate.zip\"\n",
    "if Path(ro_crate).exists():\n",
    "    Path(ro_crate).unlink()\n",
    "\n",
    "# Save output datasets\n",
    "MCCN.to_netcdf(all_data, generated_path / datacube_file)\n",
    "pd.DataFrame(data=valid_positions,columns=[\"x\",\"y\"]).to_csv(generated_path / sites_file)\n",
    "pd.DataFrame(data=masked_distances.data, index=all_data.y, columns=all_data.x).to_csv(generated_path / distances_file)\n",
    "\n",
    "# Package notebook, source data and outputs as an RO-Crate\n",
    "crate = ROCrate()\n",
    "ardc = crate.add(ContextEntity(crate, \"https://ror.org/038sjwq14\", properties={\n",
    "    \"@type\": \"Organisation\",\n",
    "    \"name\": \"Australian Research Data Commons\"\n",
    "}))\n",
    "appn = crate.add(ContextEntity(crate, \"https://ror.org/02zj7b759\", properties={\n",
    "    \"@type\": \"Organisation\",\n",
    "    \"name\": \"Australian Plant Phenomics Network\"\n",
    "}))\n",
    "dgh = crate.add(Person(crate, \"https://orcid.org/0000-0001-6492-4016\", properties={\n",
    "    \"name\": \"Donald Hobern\",\n",
    "    \"email\": \"donald.hobern@adelaide.edu.au\",\n",
    "    \"affiliation\": {\"@id\": appn.id},\n",
    "    \"jobTitle\": \"APPN Data Management Director\",\n",
    "}))\n",
    "aa = crate.add(Person(crate, \"https://github.com/alisha17\", properties={\n",
    "    \"name\": \"Alisha Aneja\",\n",
    "    \"affiliation\": {\"@id\": appn.id},\n",
    "    \"jobTitle\": \"APPN Senior Software Engineer\",\n",
    "}))\n",
    "food_security = crate.add(ContextEntity(crate, \"https://doi.org/10.47486/DC105\", properties={\n",
    "    \"@type\": \"Grant\",\n",
    "    \"name\": \"ARDC Project Code DC105: Multi-Scalar Crop Characterisation Network (MCCN)\",\n",
    "    \"funder\": {\"@id\": ardc.id}\n",
    "}))\n",
    "mccn = crate.add(ContextEntity(crate, \"https://doi.org/10.26292/8679d473\", properties={\n",
    "    \"@type\": \"ResearchProject\",\n",
    "    \"name\": \"Multi-Scalar Crop Characterisation Network (MCCN)\",\n",
    "    \"funding\": {\"@id\": food_security.id},\n",
    "    \"contactPoint\": {\"@id\": dgh.id},\n",
    "}))\n",
    "cc_by = crate.add(ContextEntity(crate, \"https://creativecommons.org/licenses/by/4.0/\", properties={\n",
    "    \"@type\": \"License\",\n",
    "    \"name\": \"Creative Commons Attribution 4.0 International (CC BY 4.0)\",\n",
    "}))\n",
    "crate_properties = crate.default_entities[0].properties()\n",
    "crate_properties |= {\n",
    "    \"name\": \"MCCN Case Study 3 - source data, notebook and results\",\n",
    "    \"description\": \"This RO-Crate is a packaged version of the Jupyter notebook for Case Study 3 of the Multiscalar Crop Characterisation Network (MCCN) project. It demonstrates the functionality of the Python packages pystac-generator and mccn-engine developed as part of this project.\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}\n",
    "cfg = crate.add(File(crate, source=config, dest_path=(Path(\"source_data\") / config), properties={\n",
    "    \"name\": \"STAC configuration file for MCCN Case Study 3\",\n",
    "    \"encodingFormat\": \"application/json\",\n",
    "    \"producer\": {\"@id\": mccn.id},\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "}))\n",
    "results_folder = Path(\"results\")\n",
    "cube = crate.add(File(crate, source=(generated_path / datacube_file), dest_path=(results_folder / datacube_file), properties={\n",
    "    \"name\": \"Xarray datacube as loaded from source data files by MCCN Case Study 3\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"application/x-netcdf\",\n",
    "    \"producer\": {\"@id\": appn.id},\n",
    "}))\n",
    "sites = crate.add(File(crate, source=(generated_path / sites_file), dest_path=(results_folder / sites_file), properties={\n",
    "    \"name\": \"CSV table of randomly selected initial site positions\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"text/csv\",\n",
    "    \"producer\": {\"@id\": appn.id},\n",
    "}))\n",
    "env = crate.add(File(crate, source=(generated_path / distances_file), dest_path=(results_folder / distances_file), properties={\n",
    "    \"name\": \"CSV table of environmental distance for points in NSW from initial site positions\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"text/csv\",\n",
    "    \"producer\": {\"@id\": appn.id},\n",
    "}))\n",
    "mccn_engine = crate.add(SoftwareApplication(crate, \"https://github.com/aus-plant-phenomics-network/mccn-engine\", properties={\n",
    "    \"name\": \"MCCN-Engine\",\n",
    "    \"description\": \"Python library for loading and combining STAC-described assets, into an xarray datacube\",\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}))\n",
    "stac_generator = crate.add(SoftwareApplication(crate, \"https://github.com/aus-plant-phenomics-network/stac-generator\", properties={\n",
    "    \"name\": \"STAC Generator\",\n",
    "    \"description\": \"Python library that combines automatically extracted geospatial information from raw assets and other user-provided metadata to build a STAC-compliant metadata record for further use\",\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}))\n",
    "crate.add(ComputationalWorkflow(crate, source=notebook, dest_path=notebook, properties={\n",
    "    \"name\": \"MCCN Case Study 3 Notebook: Select optimal survey locality\",\n",
    "    \"encodingFormat\": \"application/x-ipynb+json\",\n",
    "    \"creator\": {\"@id\": aa.id},\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"softwareRequirements\": [\n",
    "        {\"@id\": mccn_engine.id},\n",
    "        {\"@id\": stac_generator.id},\n",
    "    ],\n",
    "    \"input\": [\n",
    "        { \"@id\": cfg.id},\n",
    "    ],\n",
    "    \"output\": [\n",
    "        { \"@id\": cube.id},\n",
    "        { \"@id\": sites.id},\n",
    "        { \"@id\": env.id},\n",
    "    ],\n",
    "}))\n",
    "crate.write_zip(ro_crate)\n",
    "\n",
    "# Clean up temporary files\n",
    "shutil.rmtree(generated_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
