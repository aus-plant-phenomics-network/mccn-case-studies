{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fa3d9ed-9342-4a50-8c8f-b6e3ad16373d",
   "metadata": {},
   "source": [
    "# Case Study 4 - Validating gridded data products\n",
    "## Description \n",
    "Compare Bureau of Meteorology gridded daily maximum and minimum temperature data with data from weather stations across Western Australia.\n",
    "\n",
    "This is an example of comparing high-quality ground-based data from multiple sites with a data product from satellite imagery or data modelling, so that I can assess its precision and accuracy for estimating the same variables at other sites.\n",
    "\n",
    "## Data Sources\n",
    "The case study uses national weather data products from the Bureau of Meteorology for daily mean minimum/minimum temperature, accessible from http://www.bom.gov.au/jsp/awap/temp/index.jsp. Seven daily maximum and minimum temperature grids were downloaded for the dates 7 to 13 April 2025 inclusive. These data can be accessed in the source_data folder in the downloaded ASCII grid format (\\*.grid). These data will be loaded into the data cube as WGS84 Geotiff files. To avoid extra dependencies in this notebook, the data have already been converted using QGIS Desktop and are also included in the source_data folder (\\*.tiff).\n",
    "\n",
    "Comparison data for maximum and minimum air temperature were downloaded for all public weather stations in Western Australia from https://weather.agric.wa.gov.au/ for the 10 day period 4 to 13 April 2025. These are included in source_data as CSV files. These downloads do not include the coordinates for the weather stations. These were downloaded via the https://api.agric.wa.gov.au/v2/weather/openapi/#/Stations/getStations API method and are included in source_data as DPIRD_weather_stations.json.\n",
    "\n",
    "## Overview\n",
    "1. Convert weather station data to point measurements (longitude, latitude, date, temperature)\n",
    "2. Prepare STAC metadata records for each data source (separate records for each daily minimum and maximum layer from BOM, one for all weather station minima, and one for all weather station maxima)\n",
    "3. Load data cube\n",
    "4. Visualise cube\n",
    "5. Calculate differences between weather station values and BOM data for each station and date\n",
    "6. Identify sites with extreme differences (errors) for minimum and maximum temperature\n",
    "7. Identify sites with low differences for minimum and maximum temperature\n",
    "\n",
    "## Notes\n",
    "- Weather stations with high differences/errors are likely to have configuration of positioning issus and should not be treated as reliable.\n",
    "- Weather stations with low errors are suitable for use in local analysis.\n",
    "- The generally low difference between the measured values and the BOM products indicates the level of confidence that should be applied to use of these products for analyses where local measurements are not available.\n",
    "- In reality, at least some of these sites will have contributed to the BOM products, so the comparands are not truly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672be51",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f03814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path \n",
    "import shutil\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "\n",
    "from stac_generator.factory import StacGeneratorFactory\n",
    "from stac_generator.core.base.generator import StacSerialiser\n",
    "from stac_generator.core.base.schema import StacCollectionConfig, ColumnInfo\n",
    "from stac_generator.core.raster.schema import RasterConfig, BandInfo\n",
    "from stac_generator.core.vector.schema import VectorConfig\n",
    "from stac_generator.core.point.schema import PointConfig\n",
    "\n",
    "from mccn.client import MCCN\n",
    "\n",
    "from xarray.groupers import TimeResampler\n",
    "\n",
    "from rocrate.rocrate import ROCrate\n",
    "from rocrate.model import ComputationalWorkflow, SoftwareApplication, File, Dataset, ContextEntity, Person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42f94a",
   "metadata": {},
   "source": [
    "## Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to current folder, folder for STAC collection metadata and scratch folder for working files\n",
    "current_folder = Path.cwd()\n",
    "source_folder = current_folder/ \"source_data\"\n",
    "stac_folder = current_folder/ \"stac\"\n",
    "scratch_folder = current_folder/ \"scratch\"\n",
    "results_folder = current_folder/ \"results\"\n",
    "if not scratch_folder.exists():\n",
    "    scratch_folder.mkdir()\n",
    "current_folder = os.getcwd()\n",
    "\n",
    "# Create clean folders for outputs\n",
    "for f in [stac_folder, scratch_folder, results_folder]:\n",
    "    if f.exists():\n",
    "        shutil.rmtree(f)\n",
    "    f.mkdir()\n",
    "\n",
    "# Path to this notebook\n",
    "notebook = \"MCCN-CASE 4.ipynb\"\n",
    "\n",
    "# Paths to data from weather stations\n",
    "weather_stations = source_folder/ \"DPIRD_weather_stations.json\"\n",
    "weather_maxima_source = source_folder/ \"10DAY_MAX_AIRTEMPERATURE_20250414162054.csv\"\n",
    "weather_minima_source = source_folder/ \"10DAY_MIN_AIRTEMPERATURE_20250414162111.csv\"\n",
    "\n",
    "# Paths for outputs merging coordinates and CSV data for weather stations\n",
    "weather_maxima = scratch_folder/ \"weather_maximum_readings.csv\"\n",
    "weather_minima = scratch_folder/ \"weather_minimum_readings.csv\"\n",
    "\n",
    "# Lists of paths for Geotiffs from BOM data\n",
    "maxima_layers = {f.name: f for f in source_folder.iterdir() if not f.is_dir() and f.name.startswith(\"mean_max\") and f.name.endswith(\".tiff\")}\n",
    "minima_layers = {f.name: f for f in source_folder.iterdir() if not f.is_dir() and f.name.startswith(\"mean_min\") and f.name.endswith(\".tiff\")}\n",
    "\n",
    "# Paths to results files\n",
    "datacube_initial = results_folder/ \"temperature_study_initial.dc\"\n",
    "datacube_final = results_folder/ \"temperature_study_final.dc\"\n",
    "site_results_file = results_folder/ \"temperature_site_errors.csv\"\n",
    "\n",
    "# Path to generated RO-Crate results package\n",
    "ro_crate = Path(\"MCCN-CASE 4.RO-Crate.zip\")\n",
    "if ro_crate.exists():\n",
    "    ro_crate.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d97c3",
   "metadata": {},
   "source": [
    "## Prepare weather station data\n",
    "Read coordinates from JSON weather station metadata. Join these coordinates with the maximum and minimum air temperature readings. Drop values for the three dates preceding the BOM layers. Reshape the data to one value per row. Save using the output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d36106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station coordinates as dataframe\n",
    "station_columns = [\"Name\", \"Latitude\", \"Longitude\"]\n",
    "stations = []\n",
    "with open(weather_stations) as stations_file:\n",
    "    stations_data = json.load(stations_file)\n",
    "    for s in stations_data[\"collection\"]:\n",
    "        stations.append({\"Name\": f\"{s['stationName']} ({s['stationCode']})\", \"Latitude\": s[\"latitude\"], \"Longitude\": s[\"longitude\"]})\n",
    "df_station = pd.DataFrame(columns=station_columns, data=stations)\n",
    "\n",
    "# Process maximum air temperature data\n",
    "df_maxima = pd.merge(df_station, pd.read_csv(weather_maxima_source), how=\"left\", on=\"Name\")\n",
    "df_maxima = df_maxima.drop(columns=[\"04/04\", \"05/04\", \"06/04\"])\n",
    "df_maxima = df_maxima.rename(columns={c: f\"2025-{c[3:]}-{c[0:2]}T12:00:00Z\" for c in df_maxima.columns if c.endswith(\"04\")})\n",
    "df_maxima = pd.melt(df_maxima, id_vars=[\"Name\", \"Latitude\", \"Longitude\"], var_name=\"Date\", value_name=\"MaxTemp\").reset_index()\n",
    "df_maxima.to_csv(weather_maxima, index=False)\n",
    "\n",
    "# Process minimum air temperature data - unavailable values are mostly represented by empty strings, but sometimes by a hyphen\n",
    "df_minima = pd.merge(df_station, pd.read_csv(weather_minima_source), how=\"left\", on=\"Name\")\n",
    "df_minima = df_minima.drop(columns=[\"04/04\", \"05/04\", \"06/04\"])\n",
    "df_minima = df_minima.rename(columns={c: f\"2025-{c[3:]}-{c[0:2]}T12:00:00Z\" for c in df_minima.columns if c.endswith(\"04\")})\n",
    "df_minima = pd.melt(df_minima, id_vars=[\"Name\", \"Latitude\", \"Longitude\"], var_name=\"Date\", value_name=\"MinTemp\").reset_index()\n",
    "df_minima = df_minima.drop(df_minima[df_minima[\"MinTemp\"] == \"-\"].index)\n",
    "df_minima.to_csv(weather_minima, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5dc95",
   "metadata": {},
   "source": [
    "## Generate configuration files for STAC collection\n",
    "\n",
    "Dynamically generate STAC configuration for the whole collection and for all maximum and minimum Geotiffs and for the point data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for collection as a whole.\n",
    "collection_config = StacCollectionConfig(\n",
    "    id=\"TemperatureStudy\",\n",
    "    title=\"Datasets for national temperature data validation study\",\n",
    "    description=\"STAC records for accessing datasets to explore as part of the MCCN case study 4 relating to comparisons between national temperature data products and local weather stations\",\n",
    "    license=\"CC-BY-4.0\",\n",
    ")\n",
    "\n",
    "# Configurations for:\n",
    "# 1) seven gridded maximum temperature layers\n",
    "# 2) seven gridded minimum temperature layers\n",
    "# 3) point data and site names for maximum temperature\n",
    "# 4) point data for minimum temperature\n",
    "configurations = [\n",
    "    RasterConfig(\n",
    "        id=f.split(\".\")[0],\n",
    "        location=p.as_posix(),\n",
    "        collection_date=f\"{f[9:13]}-{f[13:15]}-{f[15:17]}\",\n",
    "        collection_time=f\"12:00:00\",\n",
    "        band_info=[\n",
    "            BandInfo(name=\"max_temp_gridded\", description=f)\n",
    "        ]\n",
    "    ) for f, p in maxima_layers.items()\n",
    "] + [\n",
    "    RasterConfig(\n",
    "        id=f\"Minimum {f.split('.')[0]}\",\n",
    "        location=p.as_posix(),\n",
    "        collection_date=f\"{f[9:13]}-{f[13:15]}-{f[15:17]}\",\n",
    "        collection_time=f\"12:00:00\",\n",
    "        band_info=[\n",
    "            BandInfo(name=\"min_temp_gridded\", description=f)\n",
    "        ]\n",
    "    ) for f, p in minima_layers.items()\n",
    "] + [\n",
    "    PointConfig(\n",
    "        id=\"WeatherStationMaxima\",\n",
    "        location=weather_maxima.as_posix(),\n",
    "        collection_date=\"2024-12-31\",\n",
    "        collection_time=\"00:00:00\",\n",
    "        X=\"Longitude\",\n",
    "        Y=\"Latitude\",\n",
    "        T=\"Date\",\n",
    "        column_info=[\n",
    "            ColumnInfo(name=\"MaxTemp\", description=f\"Weather station data\"),\n",
    "            ColumnInfo(name=\"Name\", description=f\"Weather station data\"),\n",
    "        ]\n",
    "    ),\n",
    "] + [\n",
    "    PointConfig(\n",
    "        id=\"WeatherStationMinima\",\n",
    "        location=weather_minima.as_posix(),\n",
    "        collection_date=\"2024-12-31\",\n",
    "        collection_time=\"00:00:00\",\n",
    "        X=\"Longitude\",\n",
    "        Y=\"Latitude\",\n",
    "        T=\"Date\",\n",
    "        column_info=[\n",
    "            ColumnInfo(name=\"MinTemp\", description=f\"Weather station data\"),\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Build the generator using the configurations.\n",
    "generator = StacGeneratorFactory.get_collection_generator(\n",
    "    source_configs=configurations,\n",
    "    collection_config=collection_config\n",
    ")\n",
    "\n",
    "# Serialise the STAC collection. This will generate the collection JSON file and item JSON files for each layer.\n",
    "serialiser = StacSerialiser(generator, stac_folder.as_posix())\n",
    "serialiser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a43108-71d7-443b-b25b-1e1e98ad638a",
   "metadata": {},
   "source": [
    "## Load data into data cube\n",
    "Import the data cube using a 1000*1000 grid. Group the data for the seven days as the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e2844-8507-4801-b513-295ddcf5b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load using the locally generated collection\n",
    "endpoint = stac_folder/ \"collection.json\"\n",
    "client = MCCN(endpoint, shape=(1000,1000), nodata={\"Name\": 0}, nodata_fallback=np.nan)\n",
    "ds = client.load()\n",
    "MCCN.to_netcdf(ds.copy(), datacube_initial)\n",
    "\n",
    "# Mask the 9999 nodata value in the source data\n",
    "ds[\"max_temp_gridded\"] = ds[\"max_temp_gridded\"].where(ds[\"max_temp_gridded\"] < 100, np.nan)\n",
    "ds[\"min_temp_gridded\"] = ds[\"min_temp_gridded\"].where(ds[\"min_temp_gridded\"] < 100, np.nan)\n",
    "ds = ds.where(ds > -99, np.nan)\n",
    "\n",
    "# Group layers by calendar days (timestamps do not match completely) and restrict to target dates\n",
    "ds = ds.resample(time=\"1D\").max()\n",
    "\n",
    "# Display\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcba91-b438-478c-b286-7480a914f0f2",
   "metadata": {},
   "source": [
    "## DataCube contents\n",
    "Daily mean maximum temperatures from BOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876f914-03ee-42c8-89ec-d60b3322ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"max_temp_gridded\"].plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5c18a",
   "metadata": {},
   "source": [
    "Daily mean minimum temperatures from BOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca71769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"min_temp_gridded\"].plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc425aea",
   "metadata": {},
   "source": [
    "Daily maximum air temperatures from weather stations (coarsened to 100*100 so values are visible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"MaxTemp\"].coarsen(x=10).mean().coarsen(y=10).mean().plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f528b",
   "metadata": {},
   "source": [
    "Daily minimum air temperatures from weather stations (coarsened to 100*100 so values are visible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd853315",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"MinTemp\"].coarsen(x=10).mean().coarsen(y=10).mean().plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e91c35",
   "metadata": {},
   "source": [
    "## Analyse errors\n",
    "For all points and dates with weather station data, count the number of measured values over the week and calculate the difference between the measured data and the gridded products.\n",
    "\n",
    "For each point, calculate the maximum, minimum and mean errors and the standard deviation of the errors for the seven days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations for maximum temperatures\n",
    "ds[\"max_temp_count\"] = ds[\"MaxTemp\"].count(dim=\"time\")\n",
    "ds[\"max_temp_count\"] = ds[\"max_temp_count\"].where(ds[\"max_temp_count\"] > 0, np.nan)\n",
    "ds[\"error_max_temp\"] = ds[\"MaxTemp\"].where(ds[\"MaxTemp\"] == np.nan, ds[\"MaxTemp\"] - ds[\"max_temp_gridded\"])\n",
    "ds[\"error_max_temp\"] = ds[\"error_max_temp\"].where(ds[\"error_max_temp\"] > 0, -ds[\"error_max_temp\"])\n",
    "ds[\"mean_error_max_temp\"] = ds[\"error_max_temp\"].mean(dim=\"time\")\n",
    "ds[\"max_error_max_temp\"] = ds[\"error_max_temp\"].max(dim=\"time\")\n",
    "ds[\"min_error_max_temp\"] = ds[\"error_max_temp\"].min(dim=\"time\")\n",
    "ds[\"std_error_max_temp\"] = ds[\"error_max_temp\"].std(dim=\"time\")\n",
    "\n",
    "# Calculations for minimum temperatures\n",
    "ds[\"min_temp_count\"] = ds[\"MinTemp\"].count(dim=\"time\")\n",
    "ds[\"min_temp_count\"] = ds[\"min_temp_count\"].where(ds[\"min_temp_count\"] > 0, np.nan)\n",
    "ds[\"error_min_temp\"] = ds[\"MinTemp\"].where(ds[\"MinTemp\"] == np.nan, ds[\"MinTemp\"] - ds[\"min_temp_gridded\"])\n",
    "ds[\"error_min_temp\"] = ds[\"error_min_temp\"].where(ds[\"error_min_temp\"] > 0, -ds[\"error_min_temp\"])\n",
    "ds[\"mean_error_min_temp\"] = ds[\"error_min_temp\"].mean(dim=\"time\")\n",
    "ds[\"max_error_min_temp\"] = ds[\"error_min_temp\"].max(dim=\"time\")\n",
    "ds[\"min_error_min_temp\"] = ds[\"error_min_temp\"].min(dim=\"time\")\n",
    "ds[\"std_error_min_temp\"] = ds[\"error_min_temp\"].std(dim=\"time\")\n",
    "\n",
    "# Generate pandas dataframe with values for analysis\n",
    "computed_layers = [\n",
    "    \"max_temp_count\",\n",
    "    \"mean_error_max_temp\",\n",
    "    \"max_error_max_temp\",\n",
    "    \"min_error_max_temp\",\n",
    "    \"std_error_max_temp\",\n",
    "    \"min_temp_count\",\n",
    "    \"mean_error_min_temp\",\n",
    "    \"max_error_min_temp\",\n",
    "    \"min_error_min_temp\",\n",
    "    \"std_error_min_temp\"\n",
    "]\n",
    "site_results = ds[[\"Name\"]+computed_layers].to_dataframe().drop(columns=\"spatial_ref\").dropna(axis=0).reset_index()\n",
    "site_results = site_results.loc[site_results[\"Name\"] > 0].reset_index().drop(columns=[\"index\",\"time\"]).drop_duplicates()\n",
    "\n",
    "# Restore actual station names\n",
    "site_results[\"Name\"] = site_results[\"Name\"].map(lambda x: ds.attrs[\"Name\"][int(x)])\n",
    "\n",
    "# Display\n",
    "site_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2639c-d693-4a0f-aff2-c5c5f1713025",
   "metadata": {},
   "source": [
    "## Display results\n",
    "Map the values for each calculated layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e28fba-f697-42c1-a566-c45f40f40b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in computed_layers:\n",
    "    site_results.plot(x=\"x\", y=\"y\", kind=\"scatter\", c=v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec986678",
   "metadata": {},
   "source": [
    "## Sites with high errors for mean maximum temperature\n",
    "Show details for sites that have one of the three most extreme values for any of the maximum temperature error values. Since most sites show low error values, it is likely that these sites have miscalibrated or poorly positioned sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_cases = set()\n",
    "max_temp_columns = [c for c in computed_layers if c.endswith(\"max_temp\")]\n",
    "for v in max_temp_columns:\n",
    "    extreme_cases |= set(site_results.sort_values(v, ascending=False).iloc[0:3,].index)\n",
    "extreme_sites = site_results.iloc[sorted(list(extreme_cases))][[\"x\",\"y\",\"Name\",\"max_temp_count\"]+max_temp_columns]\n",
    "pd.merge(extreme_sites, pd.read_csv(weather_maxima_source).drop(columns=[\"04/04\",\"05/04\",\"06/04\"]), how=\"left\", on=\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6211e36",
   "metadata": {},
   "source": [
    "## Sites with high errors for mean minimum temperature\n",
    "Show details for sites that have one of the three most extreme values for any of the minimum temperature error values. Since most sites show low error values, it is likely that these sites have miscalibrated or poorly positioned sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_cases = set()\n",
    "min_temp_columns = [c for c in computed_layers if c.endswith(\"min_temp\")]\n",
    "for v in max_temp_columns:\n",
    "    extreme_cases |= set(site_results.sort_values(v, ascending=False).iloc[0:3,].index)\n",
    "extreme_sites = site_results.iloc[sorted(list(extreme_cases))][[\"x\",\"y\",\"Name\",\"min_temp_count\"]+min_temp_columns]\n",
    "pd.merge(extreme_sites, pd.read_csv(weather_minima_source).drop(columns=[\"04/04\",\"05/04\",\"06/04\"]), how=\"left\", on=\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa34b5",
   "metadata": {},
   "source": [
    "## Sites with low errors\n",
    "Show details for sites that show low error values for both maximum and minimum mean temperature. These sites probably represent the best calibrated and positioned sensors and might be useful for future calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ddabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_results.loc[(site_results[\"mean_error_min_temp\"] < 0.7) & (site_results[\"mean_error_max_temp\"] < 0.7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8607b",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Beware - this will delete all generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up scratch folder\n",
    "if os.path.exists(scratch_folder):\n",
    "    shutil.rmtree(scratch_folder)\n",
    "\n",
    "# Save output datasets\n",
    "MCCN.to_netcdf(ds, datacube_final)\n",
    "site_results.to_csv(site_results_file)\n",
    "\n",
    "# Package notebook, source data and outputs as an RO-Crate\n",
    "\n",
    "cover_n_source = os.path.join(source_folder, \"vegetation_cover_northern.tif\")\n",
    "cover_s_source = os.path.join(source_folder, \"vegetation_cover_southern.tif\")\n",
    "caladenia_source = os.path.join(source_folder, \"caladenia_act.csv\")\n",
    "boundary_source = os.path.join(source_folder, \"boundary_act.geojson\")\n",
    "capad_source = os.path.join(source_folder, \"capad_act.geojson\")\n",
    "\n",
    "crate = ROCrate()\n",
    "ardc = crate.add(ContextEntity(crate, \"https://ror.org/038sjwq14\", properties={\n",
    "    \"@type\": \"Organisation\",\n",
    "    \"name\": \"Australian Research Data Commons\"\n",
    "}))\n",
    "appn = crate.add(ContextEntity(crate, \"https://ror.org/02zj7b759\", properties={\n",
    "    \"@type\": \"Organisation\",\n",
    "    \"name\": \"Australian Plant Phenomics Network\"\n",
    "}))\n",
    "dgh = crate.add(Person(crate, \"https://orcid.org/0000-0001-6492-4016\", properties={\n",
    "    \"name\": \"Donald Hobern\",\n",
    "    \"email\": \"donald.hobern@adelaide.edu.au\",\n",
    "    \"affiliation\": {\"@id\": appn.id},\n",
    "    \"jobTitle\": \"APPN Data Management Director\",\n",
    "}))\n",
    "bom = crate.add(ContextEntity(crate, \"https://ror.org/04dkp1p98\", properties={\n",
    "    \"@type\": \"Organisation\",\n",
    "    \"name\": \"Bureau of Meteorology\"\n",
    "}))\n",
    "dpird = crate.add(ContextEntity(crate, \"https://ror.org/01awp2978\", properties={\n",
    "    \"@type\": \"Organisation\",\n",
    "    \"name\": \"Department of Primary Industries and Regional Development\"\n",
    "}))\n",
    "food_security = crate.add(ContextEntity(crate, \"https://doi.org/10.47486/DC105\", properties={\n",
    "    \"@type\": \"Grant\",\n",
    "    \"name\": \"ARDC Project Code DC105: Multi-Scalar Crop Characterisation Network (MCCN)\",\n",
    "    \"funder\": {\"@id\": ardc.id}\n",
    "}))\n",
    "mccn = crate.add(ContextEntity(crate, \"https://doi.org/10.26292/8679d473\", properties={\n",
    "    \"@type\": \"ResearchActivity\",\n",
    "    \"name\": \"Multi-Scalar Crop Characterisation Network (MCCN)\",\n",
    "    \"funding\": {\"@id\": food_security.id},\n",
    "    \"contactPoint\": {\"@id\": dgh.id},\n",
    "}))\n",
    "cc_by = crate.add(ContextEntity(crate, \"https://creativecommons.org/licenses/by/4.0/\", properties={\n",
    "    \"@type\": \"License\",\n",
    "    \"name\": \"Creative Commons Attribution 4.0 International (CC BY 4.0)\",\n",
    "}))\n",
    "crate_properties = crate.default_entities[0].properties()\n",
    "crate_properties |= {\n",
    "    \"name\": \"MCCN Case Study 4 - source data, notebook and results\",\n",
    "    \"description\": \"This RO-Crate is a packaged version of the Jupyter notebook for Case Study 4 of the Multiscalar Crop Characterisation Network (MCCN) project. It demonstrates the functionality of the Python packages pystac-generator and mccn-engine developed as part of this project.\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}\n",
    "notebook_inputs = []\n",
    "bom_maxima = crate.add(Dataset(crate, source=\"http://www.bom.gov.au/jsp/awap/temp/index.jsp?&map=maxave\", properties= {\n",
    "    \"name\": f\"Daily Maximum Temperature for Australia\",\n",
    "    \"encodingFormat\": \"image/tiff\",\n",
    "    \"producer\": {\"@id\": bom.id},\n",
    "    \"citation\": \"Copyright Commonwealth of Australia 2025, Bureau of Meteorology (ABN 92 637 533 532)\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "}))\n",
    "for f, p in maxima_layers.items():\n",
    "    date_string = f\"{f[9:13]}-{f[13:15]}-{f[15:17]}\"\n",
    "    layer = crate.add(File(crate, source=p, dest_path=p.relative_to(Path.cwd()), properties={\n",
    "        \"name\": f\"Bureau of Meteorology Daily Maximum Temperature for Australia for {date_string}\",\n",
    "        \"encodingFormat\": \"image/tiff\",\n",
    "        \"isPartOf\": {\"@id\": bom_maxima.id},\n",
    "    }))\n",
    "    notebook_inputs.append({\"@id\": layer.id})\n",
    "bom_minima = crate.add(Dataset(crate, source=\"http://www.bom.gov.au/jsp/awap/temp/index.jsp?&map=minave\", properties= {\n",
    "    \"name\": f\"Daily Minimum Temperature for Australia\",\n",
    "    \"encodingFormat\": \"image/tiff\",\n",
    "    \"producer\": {\"@id\": bom.id},\n",
    "    \"citation\": \"Copyright Commonwealth of Australia 2025, Bureau of Meteorology (ABN 92 637 533 532)\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "}))\n",
    "for f, p in minima_layers.items():\n",
    "    date_string = f\"{f[9:13]}-{f[13:15]}-{f[15:17]}\"\n",
    "    layer = crate.add(File(crate, source=p, dest_path=p.relative_to(Path.cwd()), properties={\n",
    "        \"name\": f\"Bureau of Meteorology Daily Minimum Temperature for Australia for {date_string}\",\n",
    "        \"encodingFormat\": \"image/tiff\",\n",
    "        \"isPartOf\": {\"@id\": bom_minima.id},\n",
    "    }))\n",
    "    notebook_inputs.append({\"@id\": layer.id})\n",
    "layer = crate.add(File(crate, source=weather_maxima_source, dest_path=weather_maxima_source.relative_to(Path.cwd()), properties={\n",
    "    \"name\": \"WA DPIRD Daily Maximum Temperature from weather station data\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"text/csv\",\n",
    "    \"producer\": {\"@id\": dpird.id},\n",
    "    \"citation\": \"Department of Primary Industries and Regional Development, Western Australia\",\n",
    "    \"url\": {\"@id\": \"https://weather.agric.wa.gov.au/\"}\n",
    "}))\n",
    "notebook_inputs.append({\"@id\": layer.id})\n",
    "layer = crate.add(File(crate, source=weather_minima_source, dest_path=weather_minima_source.relative_to(Path.cwd()), properties={\n",
    "    \"name\": \"WA DPIRD Daily Minimum Temperature from weather station data\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"text/csv\",\n",
    "    \"producer\": {\"@id\": dpird.id},\n",
    "    \"citation\": \"Department of Primary Industries and Regional Development, Western Australia\",\n",
    "    \"url\": {\"@id\": \"https://weather.agric.wa.gov.au/\"}\n",
    "}))\n",
    "notebook_inputs.append({\"@id\": layer.id})\n",
    "initial = crate.add(File(crate, source=datacube_initial, dest_path=datacube_initial.relative_to(Path.cwd()), properties={\n",
    "    \"name\": \"Xarray datacube as loaded from source data files by MCCN Case Study 4\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"application/x-netcdf\",\n",
    "    \"producer\": {\"@id\": appn.id},\n",
    "}))\n",
    "final = crate.add(File(crate, source=datacube_final, dest_path=datacube_final.relative_to(Path.cwd()), properties={\n",
    "    \"name\": \"Xarray datacube following processing by MCCN Case Study 4\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"application/x-netcdf\",\n",
    "    \"producer\": {\"@id\": appn.id},\n",
    "}))\n",
    "errors = crate.add(File(crate, source=site_results_file, dest_path=site_results_file.relative_to(Path.cwd()), properties={\n",
    "    \"name\": \"CSV table of differences between BOM temperature products and DPIRD weather station data\",\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"encodingFormat\": \"text/csv\",\n",
    "    \"producer\": {\"@id\": appn.id},\n",
    "}))\n",
    "mccn_engine = crate.add(SoftwareApplication(crate, \"https://github.com/aus-plant-phenomics-network/mccn-engine/\", properties={\n",
    "    \"name\": \"MCCN-Engine\",\n",
    "    \"description\": \"Python library for loading and combining STAC-described assets, into an xarray datacube\",\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}))\n",
    "stac_generator = crate.add(SoftwareApplication(crate, \"https://github.com/aus-plant-phenomics-network/stac-generator\", properties={\n",
    "    \"name\": \"STAC Generator\",\n",
    "    \"description\": \"Python library that combines automatically extracted geospatial information from raw assets and other user-provided metadata to build a STAC-compliant metadata record for further use\",\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}))\n",
    "mccn_engine = crate.add(SoftwareApplication(crate, \"https://github.com/aus-plant-phenomics-network/mccn-engine/\", properties={\n",
    "    \"name\": \"MCCN-Engine\",\n",
    "    \"description\": \"Python library for loading and combining STAC-described assets, into an xarray datacube\",\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}))\n",
    "stac_generator = crate.add(SoftwareApplication(crate, \"https://github.com/aus-plant-phenomics-network/stac-generator\", properties={\n",
    "    \"name\": \"STAC Generator\",\n",
    "    \"description\": \"Python library that combines automatically extracted geospatial information from raw assets and other user-provided metadata to build a STAC-compliant metadata record for further use\",\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "}))\n",
    "crate.add(ComputationalWorkflow(crate, source=notebook, dest_path=notebook, properties={\n",
    "    \"name\": \"MCCN Case Study 4 Notebook: Validating gridded data products\",\n",
    "    \"encodingFormat\": \"application/x-ipynb+json\",\n",
    "    \"creator\": {\"@id\": dgh.id},\n",
    "    \"maintainer\": {\"@id\": mccn.id},\n",
    "    \"license\": {\"@id\": cc_by.id},\n",
    "    \"softwareRequirements\": [\n",
    "        {\"@id\": mccn_engine.id},\n",
    "        {\"@id\": stac_generator.id},\n",
    "    ],\n",
    "    \"input\": notebook_inputs,\n",
    "    \"output\": [\n",
    "        { \"@id\": initial.id},\n",
    "        { \"@id\": final.id},\n",
    "        { \"@id\": errors.id},\n",
    "    ],\n",
    "}))\n",
    "\n",
    "crate.write_zip(ro_crate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
