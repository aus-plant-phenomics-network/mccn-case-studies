{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fa3d9ed-9342-4a50-8c8f-b6e3ad16373d",
   "metadata": {},
   "source": [
    "# Case Study 4 - Validating gridded data products\n",
    "## Description \n",
    "As a user of spatial data products (satellite or modelled), I want to compare high-quality ground-based data from multiple sites with the product, so that I can assess its precision and accuracy for estimating the same variables at other sites.\n",
    "## Case Breakdown \n",
    "- **Actors:** Gridded Data User\n",
    "- **Goals:** Finding correlations between gridded data and ground-based data\n",
    "- **Scope:** National, point-based\n",
    "## Generalised case\n",
    "I want to compare measurements from a gridded data product with actual on-ground measurements from different sites and report mean and standard deviation for the error.\n",
    "## Comparable cases\n",
    "- I want to compare local weather station values at APPN and/or TERN sites with the associated daily measurememts from national weather datasets (BOM).\n",
    "## Stakeholders \n",
    "- **Name:** Donald Hobern\n",
    "- **Contact:** donald.hobern@adelaide.edu.au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806db0de-ec5a-471b-97ba-ea12f54e24dc",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "The case study uses national weather data products from the Bureau of Meteorology for daily mean minimum/minimum temperature, accessible from http://www.bom.gov.au/jsp/awap/temp/index.jsp. Seven daily maximum and minimum temperature grids were downloaded for the dates 7 to 13 April 2025 inclusive. These data can be accessed in the source_data folder in the downloaded ASCII grid format (\\*.grid). These data will be loaded into the data cube as WGS84 Geotiff files. To avoid extra dependencies in this notebook, the data have already been converted using QGIS Desktop and are also included in the source_data folder (\\*.tiff).\n",
    "\n",
    "Comparison data for maximum and minimum air temperature were downloaded for all public weather stations in Western Australia from https://weather.agric.wa.gov.au/ for the 10 day period 4 to 13 April 2025. These are included in source_data as CSV files. These downloads do not include the coordinates for the weather stations. These were downloaded via the https://api.agric.wa.gov.au/v2/weather/openapi/#/Stations/getStations API method and are included in source_data as DPIRD_weather_stations.json."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672be51",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f03814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path \n",
    "import shutil\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "\n",
    "from stac_generator.factory import StacGeneratorFactory\n",
    "from stac_generator.core.base.generator import StacSerialiser\n",
    "from stac_generator.core.base.schema import StacCollectionConfig, ColumnInfo\n",
    "from stac_generator.core.raster.schema import RasterConfig, BandInfo\n",
    "from stac_generator.core.vector.schema import VectorConfig\n",
    "from stac_generator.core.point.schema import PointConfig\n",
    "\n",
    "from mccn.client import MCCN\n",
    "\n",
    "from xarray.groupers import TimeResampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42f94a",
   "metadata": {},
   "source": [
    "## Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to current folder and scratch folder for working files\n",
    "current_folder = Path.cwd()\n",
    "source_folder = current_folder / \"source_data\"\n",
    "scratch_folder = current_folder/\"scratch\"\n",
    "if not scratch_folder.exists():\n",
    "    scratch_folder.mkdir()\n",
    "\n",
    "\n",
    "# Paths to data from weather stations\n",
    "weather_stations = source_folder/ \"DPIRD_weather_stations.json\"\n",
    "weather_maxima_source = source_folder/ \"10DAY_MAX_AIRTEMPERATURE_20250414162054.csv\"\n",
    "weather_minima_source = source_folder/ \"10DAY_MIN_AIRTEMPERATURE_20250414162111.csv\"\n",
    "\n",
    "# Paths for outputs merging coordinates and CSV data for weather stations\n",
    "weather_maxima = scratch_folder/ \"weather_maximum_readings.csv\"\n",
    "weather_minima = scratch_folder/ \"weather_minimum_readings.csv\"\n",
    "\n",
    "# Lists of paths for Geotiffs from BOM data\n",
    "maxima_layers = {f.name: f for f in source_folder.iterdir() if not f.is_dir() and f.name.startswith(\"mean_max\") and f.name.endswith(\".tiff\")}\n",
    "minima_layers = {f.name: f for f in source_folder.iterdir() if not f.is_dir() and f.name.startswith(\"mean_min\") and f.name.endswith(\".tiff\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d97c3",
   "metadata": {},
   "source": [
    "## Prepare weather station data\n",
    "Read coordinates from JSON weather station metadata. Join these coordinates with the maximum and minimum air temperature readings. Drop values for the three dates preceding the BOM layers. Reshape the data to one value per row. Save using the output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d36106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station coordinates as dataframe\n",
    "station_columns = [\"Name\", \"Latitude\", \"Longitude\"]\n",
    "stations = []\n",
    "with open(weather_stations) as stations_file:\n",
    "    stations_data = json.load(stations_file)\n",
    "    for s in stations_data[\"collection\"]:\n",
    "        stations.append({\"Name\": f\"{s['stationName']} ({s['stationCode']})\", \"Latitude\": s[\"latitude\"], \"Longitude\": s[\"longitude\"]})\n",
    "df_station = pd.DataFrame(columns=station_columns, data=stations)\n",
    "\n",
    "# Process maximum air temperature data\n",
    "df_maxima = pd.merge(df_station, pd.read_csv(weather_maxima_source), how=\"left\", on=\"Name\")\n",
    "df_maxima = df_maxima.drop(columns=[\"04/04\", \"05/04\", \"06/04\"])\n",
    "df_maxima = df_maxima.rename(columns={c: f\"2025-{c[3:]}-{c[0:2]}T12:00:00Z\" for c in df_maxima.columns if c.endswith(\"04\")})\n",
    "df_maxima = pd.melt(df_maxima, id_vars=[\"Name\", \"Latitude\", \"Longitude\"], var_name=\"Date\", value_name=\"MaxTemp\").reset_index()\n",
    "df_maxima.to_csv(weather_maxima, index=False)\n",
    "\n",
    "# Process minimum air temperature data\n",
    "df_minima = pd.merge(df_station, pd.read_csv(weather_minima_source), how=\"left\", on=\"Name\")\n",
    "df_minima = df_minima.drop(columns=[\"04/04\", \"05/04\", \"06/04\"])\n",
    "df_minima = df_minima.rename(columns={c: f\"2025-{c[3:]}-{c[0:2]}T12:00:00Z\" for c in df_minima.columns if c.endswith(\"04\")})\n",
    "df_minima = pd.melt(df_minima, id_vars=[\"Name\", \"Latitude\", \"Longitude\"], var_name=\"Date\", value_name=\"MinTemp\").reset_index()\n",
    "# Unavailable values are mostly represented by empty strings, but sometime by a hyphen.\n",
    "df_minima = df_minima.drop(df_minima[df_minima[\"MinTemp\"] == \"-\"].index)\n",
    "df_minima.to_csv(weather_minima, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5dc95",
   "metadata": {},
   "source": [
    "## Generate configuration files for STAC collection\n",
    "\n",
    "Dynamically generate STAC configuration for the whole collection and for all maximum and minimum Geotiffs and for the point data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for collection as a whole.\n",
    "collection_config = StacCollectionConfig(\n",
    "    id=\"TemperatureStudy\",\n",
    "    title=\"Datasets for national temperature data validation study\",\n",
    "    description=\"STAC records for accessing datasets to explore as part of the MCCN case study 4 relating to comparisons between national temperature data products and local weather stations\",\n",
    "    license=\"CC-BY-4.0\",\n",
    ")\n",
    "\n",
    "# Configurations for:\n",
    "# 1) seven gridded maximum temperature layers\n",
    "# 2) seven gridded minimum temperature layers\n",
    "# 3) point data and site names for maximum temperature\n",
    "# 4) point data for minimum temperature\n",
    "configurations = [\n",
    "    RasterConfig(\n",
    "        id=f.split(\".\")[0],\n",
    "        location=p.as_posix(),\n",
    "        collection_date=f\"{f[9:13]}-{f[13:15]}-{f[15:17]}\",\n",
    "        collection_time=f\"12:00:00\",\n",
    "        band_info=[\n",
    "            BandInfo(name=\"max_temp_gridded\", description=f)\n",
    "        ]\n",
    "    ) for f, p in maxima_layers.items()\n",
    "] + [\n",
    "    RasterConfig(\n",
    "        id=f\"Minimum {f.split('.')[0]}\",\n",
    "        location=p.as_posix(),\n",
    "        collection_date=f\"{f[9:13]}-{f[13:15]}-{f[15:17]}\",\n",
    "        collection_time=f\"12:00:00\",\n",
    "        band_info=[\n",
    "            BandInfo(name=\"min_temp_gridded\", description=f)\n",
    "        ]\n",
    "    ) for f, p in minima_layers.items()\n",
    "] + [\n",
    "    PointConfig(\n",
    "        id=\"WeatherStationMaxima\",\n",
    "        location=weather_maxima.as_posix(),\n",
    "        collection_date=\"2024-12-31\",\n",
    "        collection_time=\"00:00:00\",\n",
    "        X=\"Longitude\",\n",
    "        Y=\"Latitude\",\n",
    "        T=\"Date\",\n",
    "        column_info=[\n",
    "            ColumnInfo(name=\"MaxTemp\", description=f\"Weather station data\"),\n",
    "            ColumnInfo(name=\"Name\", description=f\"Weather station data\"),\n",
    "        ]\n",
    "    ),\n",
    "] + [\n",
    "    PointConfig(\n",
    "        id=\"WeatherStationMinima\",\n",
    "        location=weather_minima.as_posix(),\n",
    "        collection_date=\"2024-12-31\",\n",
    "        collection_time=\"00:00:00\",\n",
    "        X=\"Longitude\",\n",
    "        Y=\"Latitude\",\n",
    "        T=\"Date\",\n",
    "        column_info=[\n",
    "            ColumnInfo(name=\"MinTemp\", description=f\"Weather station data\"),\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Build the generator using the configurations.\n",
    "generator = StacGeneratorFactory.get_collection_generator(\n",
    "    source_configs=configurations,\n",
    "    collection_config=collection_config\n",
    ")\n",
    "\n",
    "# Serialise the STAC collection. This will generate the collection JSON file and item JSON files for each layer.\n",
    "serialiser = StacSerialiser(generator, scratch_folder.as_posix())\n",
    "serialiser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a43108-71d7-443b-b25b-1e1e98ad638a",
   "metadata": {},
   "source": [
    "## Load data into data cube\n",
    "Import the data cube using a 1000*1000 grid. Group the data for the seven days as the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e2844-8507-4801-b513-295ddcf5b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load using the locally generated collection\n",
    "endpoint = os.path.join(scratch_folder, \"collection.json\")\n",
    "client = MCCN(endpoint, shape=(1000,1000), nodata={\"Name\": 0}, nodata_fallback=np.nan)\n",
    "ds = client.load()\n",
    "\n",
    "# Mask the 9999 nodata value in the source data\n",
    "ds[\"max_temp_gridded\"] = ds[\"max_temp_gridded\"].where(ds[\"max_temp_gridded\"] < 100, np.nan)\n",
    "ds[\"min_temp_gridded\"] = ds[\"min_temp_gridded\"].where(ds[\"min_temp_gridded\"] < 100, np.nan)\n",
    "ds = ds.where(ds > -99, np.nan)\n",
    "\n",
    "# Group layers by calendar days (timestamps do not match completely) and restrict to target dates\n",
    "ds = ds.resample(time=\"1D\").max()\n",
    "#ds = ds.sel(time=slice(\"2025-04-07\", \"2025-04-13\"))\n",
    "\n",
    "\n",
    "# Display\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcba91-b438-478c-b286-7480a914f0f2",
   "metadata": {},
   "source": [
    "## DataCube contents\n",
    "Daily mean maximum temperatures from BOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876f914-03ee-42c8-89ec-d60b3322ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"max_temp_gridded\"].plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5c18a",
   "metadata": {},
   "source": [
    "Daily mean minimum temperatures from BOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca71769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"min_temp_gridded\"].plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc425aea",
   "metadata": {},
   "source": [
    "Daily maximum air temperatures from weather stations (coarsened to 100*100 so values are visible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"MaxTemp\"].coarsen(x=10).mean().coarsen(y=10).mean().plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f528b",
   "metadata": {},
   "source": [
    "Daily minimum air temperatures from weather stations (coarsened to 100*100 so values are visible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd853315",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"MinTemp\"].coarsen(x=10).mean().coarsen(y=10).mean().plot(x=\"x\", y=\"y\", col=\"time\", col_wrap=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e91c35",
   "metadata": {},
   "source": [
    "## Analyse errors\n",
    "For all points and dates with weather station data, count the number of measured values over the week andcalculate the difference between the measured data and the gridded products.\n",
    "\n",
    "For each point, calculate the maximum, minimum and mean errors and the standard deviation of the errors for the seven days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations for maximum temperatures\n",
    "ds[\"max_temp_count\"] = ds[\"MaxTemp\"].count(dim=\"time\")\n",
    "ds[\"max_temp_count\"] = ds[\"max_temp_count\"].where(ds[\"max_temp_count\"] > 0, np.nan)\n",
    "ds[\"error_max_temp\"] = ds[\"MaxTemp\"].where(ds[\"MaxTemp\"] == np.nan, ds[\"MaxTemp\"] - ds[\"max_temp_gridded\"])\n",
    "ds[\"error_max_temp\"] = ds[\"error_max_temp\"].where(ds[\"error_max_temp\"] > 0, -ds[\"error_max_temp\"])\n",
    "ds[\"mean_error_max_temp\"] = ds[\"error_max_temp\"].mean(dim=\"time\")\n",
    "ds[\"max_error_max_temp\"] = ds[\"error_max_temp\"].max(dim=\"time\")\n",
    "ds[\"min_error_max_temp\"] = ds[\"error_max_temp\"].min(dim=\"time\")\n",
    "ds[\"std_error_max_temp\"] = ds[\"error_max_temp\"].std(dim=\"time\")\n",
    "\n",
    "# Calculations for minimum temperatures\n",
    "ds[\"min_temp_count\"] = ds[\"MinTemp\"].count(dim=\"time\")\n",
    "ds[\"min_temp_count\"] = ds[\"min_temp_count\"].where(ds[\"min_temp_count\"] > 0, np.nan)\n",
    "ds[\"error_min_temp\"] = ds[\"MinTemp\"].where(ds[\"MinTemp\"] == np.nan, ds[\"MinTemp\"] - ds[\"min_temp_gridded\"])\n",
    "ds[\"error_min_temp\"] = ds[\"error_min_temp\"].where(ds[\"error_min_temp\"] > 0, -ds[\"error_min_temp\"])\n",
    "ds[\"mean_error_min_temp\"] = ds[\"error_min_temp\"].mean(dim=\"time\")\n",
    "ds[\"max_error_min_temp\"] = ds[\"error_min_temp\"].max(dim=\"time\")\n",
    "ds[\"min_error_min_temp\"] = ds[\"error_min_temp\"].min(dim=\"time\")\n",
    "ds[\"std_error_min_temp\"] = ds[\"error_min_temp\"].std(dim=\"time\")\n",
    "\n",
    "# Generate pandas dataframe with values for analysis\n",
    "computed_layers = [\n",
    "    \"max_temp_count\",\n",
    "    \"mean_error_max_temp\",\n",
    "    \"max_error_max_temp\",\n",
    "    \"min_error_max_temp\",\n",
    "    \"std_error_max_temp\",\n",
    "    \"min_temp_count\",\n",
    "    \"mean_error_min_temp\",\n",
    "    \"max_error_min_temp\",\n",
    "    \"min_error_min_temp\",\n",
    "    \"std_error_min_temp\"\n",
    "]\n",
    "da = ds[[\"Name\"]+computed_layers].to_dataframe().drop(columns=\"spatial_ref\").dropna(axis=0).reset_index()\n",
    "da = da.loc[da[\"Name\"] > 0].reset_index().drop(columns=[\"index\",\"time\"]).drop_duplicates()\n",
    "\n",
    "# Restore actual station names\n",
    "da[\"Name\"] = da[\"Name\"].map(lambda x: ds.attrs[\"Name\"][int(x)])\n",
    "\n",
    "# Display\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2639c-d693-4a0f-aff2-c5c5f1713025",
   "metadata": {},
   "source": [
    "## Display results\n",
    "Map the values for each calculated layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e28fba-f697-42c1-a566-c45f40f40b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in computed_layers:\n",
    "    da.plot(x=\"x\", y=\"y\", kind=\"scatter\", c=v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec986678",
   "metadata": {},
   "source": [
    "## Sites with high errors for mean maximum temperature\n",
    "Show details for sites that have one of the three most extreme values for any of the maximum temperature error values. Since most sites show low error values, it is likely that these sites have miscalibrated or poorly positioned sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_cases = set()\n",
    "max_temp_columns = [c for c in computed_layers if c.endswith(\"max_temp\")]\n",
    "for v in max_temp_columns:\n",
    "    extreme_cases |= set(da.sort_values(v, ascending=False).iloc[0:3,].index)\n",
    "extreme_sites = da.iloc[sorted(list(extreme_cases))][[\"x\",\"y\",\"Name\",\"max_temp_count\"]+max_temp_columns]\n",
    "pd.merge(extreme_sites, pd.read_csv(weather_maxima_source).drop(columns=[\"04/04\",\"05/04\",\"06/04\"]), how=\"left\", on=\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6211e36",
   "metadata": {},
   "source": [
    "## Sites with high errors for mean minimum temperature\n",
    "Show details for sites that have one of the three most extreme values for any of the minimum temperature error values. Since most sites show low error values, it is likely that these sites have miscalibrated or poorly positioned sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_cases = set()\n",
    "min_temp_columns = [c for c in computed_layers if c.endswith(\"min_temp\")]\n",
    "for v in max_temp_columns:\n",
    "    extreme_cases |= set(da.sort_values(v, ascending=False).iloc[0:3,].index)\n",
    "extreme_sites = da.iloc[sorted(list(extreme_cases))][[\"x\",\"y\",\"Name\",\"min_temp_count\"]+min_temp_columns]\n",
    "pd.merge(extreme_sites, pd.read_csv(weather_minima_source).drop(columns=[\"04/04\",\"05/04\",\"06/04\"]), how=\"left\", on=\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa34b5",
   "metadata": {},
   "source": [
    "## Sites with low errors\n",
    "Show details for sites that show low error values for both maximum and minimum mean temperature. These sites probably represent the best calibrated and positioned sensors and might be useful for future calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ddabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.loc[(da[\"mean_error_min_temp\"] < 0.7) & (da[\"mean_error_max_temp\"] < 0.7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8607b",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Beware - this will delete all generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up scratch folder\n",
    "\n",
    "shutil.rmtree(scratch_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
